{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Assignment 1</center>\n",
    "<right><b>Bhumi Patel (B00824756)</b></right>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pprint import pprint\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# getlist of all files in all folders\n",
    "def getListofFileFunction():\n",
    "    \n",
    "    filelist=[];\n",
    "    for i in range(10,31):\n",
    "        filename=\"199703\"+str(i)+\"/*.xml\";\n",
    "        files=glob.glob(filename);\n",
    "        filelist.append(files); \n",
    "        \n",
    "    return filelist\n",
    " \n",
    "fileList=getListofFileFunction();    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46423, 6)\n"
     ]
    }
   ],
   "source": [
    "# function to get dataframe from xml files \n",
    "def XmlToDataframeFunction(fileList,dfColumnList):\n",
    "    \n",
    "\n",
    "    xml_df = pd.DataFrame(columns=dfColumnList);\n",
    "    \n",
    "    for folder in fileList:\n",
    "        \n",
    "        for i in folder:\n",
    "            \n",
    "            fileName= i.split(\"/\",1)[1];\n",
    "            root = ET.parse(i).getroot();\n",
    "            date=\"\"\n",
    "            itemId=root.get('itemid');\n",
    "            headline=root.find(\"headline\").text\n",
    "            text_array=root.find(\"text\")\n",
    "            \n",
    "            text=\"\"\n",
    "            for i in text_array:\n",
    "                text=text+i.text;\n",
    "\n",
    "            meta_data=root.find(\"metadata\");\n",
    "            \n",
    "            topics=[];\n",
    "            for i in meta_data:\n",
    "                if i.get(\"class\")==\"bip:topics:1.0\":\n",
    "                    for j in i:\n",
    "                        topics.append(j.get('code'));\n",
    "                if i.get(\"element\")==\"dc.date.published\":\n",
    "                    date=i.get('value');\n",
    "\n",
    "            xml_df = xml_df.append(\n",
    "                        pd.Series([itemId,headline,text,topics,date,fileName], index=dfColumnList),\n",
    "                        ignore_index=True)\n",
    "\n",
    "    return xml_df;\n",
    "\n",
    "# list of column in dataframe\n",
    "dfcols = ['itemId', 'headline', 'text','topics','date','fileName'];\n",
    "xml_df=XmlToDataframeFunction(fileList,dfcols)\n",
    "pprint(xml_df.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       itemId                                           headline  \\\n",
      "0      431661  RTRS-Australia base metal producer prices - Ma...   \n",
      "1      431382         SocGen ups TF1 to outperform from neutral.   \n",
      "2      431457  Dutch money market in suspense over possible h...   \n",
      "3      431985                 Iran joins Islamic insurance body.   \n",
      "4      431727  FOCUS - Japan finalises laws aimed at MOF's po...   \n",
      "...       ...                                                ...   \n",
      "46418  475604  Curfew in northwest Cameroon, gunmen kill gend...   \n",
      "46419  475610           Gunmen target Cameroon forces, kill two.   \n",
      "46420  475756          EgyptAir takes Libyan pilgrims to Jeddah.   \n",
      "46421  475560   SOCCER-TUNISIA FIRST DIVISION RESULTS/STANDINGS.   \n",
      "46422  475801     Israeli-Arab tensions mar Easter in Jerusalem.   \n",
      "\n",
      "                                                    text  \\\n",
      "0      Australian base metal producer prices:\\t\\t\\t\\t...   \n",
      "1      Societe Generale raised its recommendation for...   \n",
      "2      Trade on the Dutch money market was quiet on M...   \n",
      "3      Iran has joined the Islamic Corporation for th...   \n",
      "4      Japan on Monday finalised bills aimed at trimm...   \n",
      "...                                                  ...   \n",
      "46418  The governor of Cameroon's volatile English-sp...   \n",
      "46419  Unidentified gunmen have killed at least two p...   \n",
      "46420  The first EgyptAir flight carrying Libyans to ...   \n",
      "46421  Results of Tunisian firstdivision soccer match...   \n",
      "46422  Hundreds of pilgrims on Easter Sunday prayed i...   \n",
      "\n",
      "                              topics        date          fileName  \n",
      "0                  [M14, M142, MCAT]  1997-03-10  431661newsML.xml  \n",
      "1                  [C15, C152, CCAT]  1997-03-10  431382newsML.xml  \n",
      "2                  [M13, M131, MCAT]  1997-03-10  431457newsML.xml  \n",
      "3       [C13, CCAT, E51, E512, ECAT]  1997-03-10  431985newsML.xml  \n",
      "4             [C13, CCAT, E12, ECAT]  1997-03-10  431727newsML.xml  \n",
      "...                              ...         ...               ...  \n",
      "46418             [GCAT, GPOL, GVIO]  1997-03-30  475604newsML.xml  \n",
      "46419                   [GCAT, GVIO]  1997-03-30  475610newsML.xml  \n",
      "46420  [C21, CCAT, GCAT, GDIP, GREL]  1997-03-30  475756newsML.xml  \n",
      "46421                   [GCAT, GSPO]  1997-03-30  475560newsML.xml  \n",
      "46422             [GCAT, GREL, GVIO]  1997-03-30  475801newsML.xml  \n",
      "\n",
      "[46423 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(xml_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bip Topics \n",
    "- There are 101 different news type in dataset.\n",
    "- Removed rows which does not contain any Biptopics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E512', 'G151', 'M132', 'C183', 'GREL', 'GFAS', 'GODD', 'G156', 'M12', 'E14', 'E411', 'C13', 'GTOUR', 'M13', 'M14', 'E141', 'GSPO', 'ECAT', 'GHEA', 'E211', 'C22', 'C32', 'C24', 'E31', 'GCRIM', 'E212', 'E513', 'GENT', 'M131', 'GJOB', 'E21', 'G158', 'C181', 'C18', 'C174', 'E71', 'GDIP', 'C14', 'C313', 'G15', 'E132', 'G155', 'C331', 'GPRO', 'E142', 'GENV', 'C31', 'GVOTE', 'E11', 'GPOL', 'CCAT', 'G153', 'GDEF', 'E13', 'C21', 'C23', 'C172', 'C34', 'E143', 'C182', 'C411', 'E61', 'E313', 'GOBIT', 'M11', 'C173', 'E511', 'C15', 'E41', 'GSCI', 'C33', 'G157', 'M143', 'GWEA', 'C312', 'GDIS', 'C12', 'E51', 'G154', 'GCAT', 'C311', 'GWELF', 'C17', 'C171', 'G152', 'E311', 'M142', 'C11', 'M141', 'C152', 'E12', 'GVIO', 'C41', 'C16', 'MCAT', 'C1511', 'E121', 'E131', 'C151', 'E312', 'C42']\n",
      "no of unique news type 101\n"
     ]
    }
   ],
   "source": [
    "df=xml_df.copy()\n",
    "\n",
    "#Remove rows which does not contain any news topics.\n",
    "df=df[df['topics'].map(lambda d: len(d)) > 0]\n",
    "\n",
    "# function to get unique news topic.\n",
    "def getBipTopicsList(df_topics):\n",
    "    \n",
    "    topics_value=[];\n",
    "    for i in df_topics:\n",
    "        for j in i:\n",
    "            topics_value.append(j);\n",
    "\n",
    "    unique_topic_value=set(topics_value);\n",
    "    return list(unique_topic_value)\n",
    "\n",
    "topics_list=getBipTopicsList(xml_df[\"topics\"])\n",
    "print(topics_list)\n",
    "print(\"no of unique news type\",len(topics_list));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words remove:\n",
    "- Removed stop words using NLTK library.\n",
    "- perform words steamming \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to remove stopwords and perform stemming on words. \n",
    "def removeStopWord(df_text):\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words=set(stopwords.words(\"english\"))\n",
    "    cleaned_text=[]\n",
    "\n",
    "    for data in df_text:\n",
    "        tokenized_word=word_tokenize(data)\n",
    "        temp_wordlist=[]\n",
    "\n",
    "        for w in tokenized_word:\n",
    "\n",
    "            #check if word is stop_words and alphabetic words \n",
    "             if w.lower() not in stop_words and w.isalpha():\n",
    "                    \n",
    "                #Stem the words\n",
    "                word_Final = stemmer.stem(w)\n",
    "                temp_wordlist.append(word_Final)\n",
    "\n",
    "        temp=' '.join(temp_wordlist)\n",
    "        cleaned_text.append(temp)\n",
    "        \n",
    "    return cleaned_text\n",
    "\n",
    "cleaned_text=removeStopWord(df['text'])\n",
    "df['text']=list(cleaned_text);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        australian base metal produc price per tonn co...\n",
      "1        societ general rais recommend share privat fre...\n",
      "2        trade dutch money market quiet monday morn mar...\n",
      "3        iran join islam corpor insur invest export cre...\n",
      "4        japan monday finalis bill aim trim mighti fina...\n",
      "                               ...                        \n",
      "46418    governor cameroon volatil provinc sunday decla...\n",
      "46419    unidentifi gunmen kill least two paramilitari ...\n",
      "46420    first egyptair flight carri libyan saudi arabi...\n",
      "46421    result tunisian firstdivis soccer match play w...\n",
      "46422    hundr pilgrim easter sunday pray jerusalem sit...\n",
      "Name: text, Length: 46308, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['text']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction \n",
    "- I extract text feature using TfidfVector\n",
    "- I took first bip topics from documnets' list of bip-topics\n",
    "- I perform label encoding on Labels data which converts string data to numaric data.\n",
    "- I took 10000 data from whole dataset to perform classification model due to hight execution time in model training and model tunning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               features  labels\n",
      "0       (0, 21932)\\t0.056011322317093104\\n  (0, 3153...      96\n",
      "1       (0, 23733)\\t0.13967124510306675\\n  (0, 9464)...       4\n",
      "2       (0, 10998)\\t0.045211422803396774\\n  (0, 1201...      93\n",
      "3       (0, 2528)\\t0.10733212771373776\\n  (0, 10596)...       2\n",
      "4       (0, 15084)\\t0.05700991945708145\\n  (0, 32833...       2\n",
      "...                                                 ...     ...\n",
      "9995    (0, 1705)\\t0.20164007794960054\\n  (0, 231)\\t...      35\n",
      "9996    (0, 4976)\\t0.16110822626407223\\n  (0, 16631)...      96\n",
      "9997    (0, 23456)\\t0.11064385262493953\\n  (0, 34882...       4\n",
      "9998    (0, 3603)\\t0.21281129354295159\\n  (0, 19282)...       4\n",
      "9999    (0, 26263)\\t0.3688438615531311\\n  (0, 5189)\\...       9\n",
      "\n",
      "[10000 rows x 2 columns]\n",
      "  (0, 21932)\t0.056011322317093104\n",
      "  (0, 31534)\t0.1360368192100831\n",
      "  (0, 18605)\t0.17769005526330656\n",
      "  (0, 34186)\t0.10416676655157624\n",
      "  (0, 36324)\t0.179682640723308\n",
      "  (0, 24585)\t0.23195226347281497\n",
      "  (0, 24990)\t0.12204741141873757\n",
      "  (0, 23833)\t0.25104991777322666\n",
      "  (0, 28462)\t0.1582738761303105\n",
      "  (0, 7026)\t0.30514555541437643\n",
      "  (0, 19465)\t0.21297106372545185\n",
      "  (0, 27376)\t0.1937569548719917\n",
      "  (0, 34919)\t0.49305768340795153\n",
      "  (0, 5307)\t0.20325803138313786\n",
      "  (0, 11038)\t0.1356161684262778\n",
      "  (0, 9656)\t0.10355154278248378\n",
      "  (0, 5649)\t0.08862150484807654\n",
      "  (0, 18832)\t0.0965646041183537\n",
      "  (0, 14336)\t0.08685913637933194\n",
      "  (0, 7030)\t0.25104991777322666\n",
      "  (0, 32744)\t0.20606985187554674\n",
      "  (0, 24165)\t0.1615550712241042\n",
      "  (0, 25350)\t0.13740416488273688\n",
      "  (0, 25484)\t0.09888541162056233\n",
      "  (0, 20223)\t0.13520184345840014\n",
      "  :\t:\n",
      "  (9998, 26842)\t0.05760291597034153\n",
      "  (9998, 6945)\t0.06891377265330781\n",
      "  (9998, 27887)\t0.05760279093080163\n",
      "  (9998, 23283)\t0.13118080392834358\n",
      "  (9998, 28990)\t0.11217522126821906\n",
      "  (9998, 26458)\t0.11028919604354373\n",
      "  (9998, 25350)\t0.05575663531038621\n",
      "  (9999, 26263)\t0.3688438615531311\n",
      "  (9999, 5189)\t0.40606830684733636\n",
      "  (9999, 19933)\t0.3901828664991878\n",
      "  (9999, 20998)\t0.22118641663928917\n",
      "  (9999, 21313)\t0.21970514245461703\n",
      "  (9999, 15909)\t0.2814738136852095\n",
      "  (9999, 7879)\t0.16657868838192305\n",
      "  (9999, 36073)\t0.16717405240994235\n",
      "  (9999, 15733)\t0.16084734061077324\n",
      "  (9999, 8365)\t0.18406468003338747\n",
      "  (9999, 7206)\t0.2592841237102783\n",
      "  (9999, 1181)\t0.17965068202542397\n",
      "  (9999, 27942)\t0.2722528423453931\n",
      "  (9999, 30598)\t0.12031642377053459\n",
      "  (9999, 21883)\t0.104199963948173\n",
      "  (9999, 28834)\t0.15471369649083966\n",
      "  (9999, 26250)\t0.1313761858895523\n",
      "  (9999, 19465)\t0.12164515099409133\n"
     ]
    }
   ],
   "source": [
    "#get lables value, I took just first news topic from list of topics in one document.\n",
    "def getlableColumn(df_topics):\n",
    "    \n",
    "    topic_list=[];\n",
    "\n",
    "    for i in df_topics:\n",
    "        if len(i)!=0:\n",
    "            topic_list.append(i[0]);\n",
    "        else:\n",
    "            topic_list.append(\"\");\n",
    "    \n",
    "    lbl_list=LabelEncoder()\n",
    "    lbl_list.fit(topics_list);\n",
    "    topic_list=lbl_list.transform(topic_list)\n",
    "    \n",
    "    return topic_list\n",
    " \n",
    "#function to get dataframe which contain feature and lable.\n",
    "#Feature=perform TfidfVectorizer to extract feature from text \n",
    "\n",
    "def getFeatureAndLable(df):\n",
    "    \n",
    "    cleaned_text=df['text']\n",
    "    df_topics=df['topics']\n",
    "    df_new = pd.DataFrame()\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    words_tfIdf = vectorizer.fit_transform(cleaned_text)\n",
    "    df_new['features'] = list(words_tfIdf);\n",
    "    df_new['labels']=getlableColumn(df_topics);\n",
    "    return words_tfIdf,df_new\n",
    "\n",
    "df_model=df[:10000]\n",
    "words_tfIdf,df_new=getFeatureAndLable(df_model)\n",
    "print(df_new);\n",
    "print(words_tfIdf);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide your data into a training and test set\n",
    "\n",
    "Methods available :\n",
    " 1. Hold-out\n",
    " 2. Cross validation \n",
    " \n",
    " ### Hold-out :\n",
    "- In hold-out method, Data is split into train and test. Train data will be used to train model.Test data is unseen data for model, it will be used to check performance of model.\n",
    "- This method is good for large number of dataset because it does not use every single dataset to train the model.If the size of the dataset is crucial then cross-validation works better.\n",
    "\n",
    " ### Cross validation :\n",
    "- In Cross-validation method, Data is split in to K groups.Each time 1/K of the data is used for evalution.\n",
    "- In this method, Data is used very efficiently because every data is used to train model.But for large dataset it will take higher time.Cross validation is computationally expensive.\n",
    "\n",
    " \n",
    "#### I used Hold-Out method to split my data into training and testset.\n",
    "- I have 10000 dataset, which is very high. Cross validation takes very high time in computation with large dataset.On other hand Hold-out method is good to use when we have large amount of dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "#split the Data\n",
    "Train_X, Test_X, Train_Y, Test_Y =train_test_split(words_tfIdf,df_new['labels'],test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classifier evaluation metrics: \n",
    "- <b> I used F-score with average='micro'</b>\n",
    "- F-sore :  F1 score is a weighted average of the precision and recall,It works better when data has uneven class distribution.\n",
    "\n",
    "   - Precision gives ration of correctly predicted positive observations to the total predicted positive observations\n",
    "   - Recall gives the ratio of correctly predicted positive observations to the all observations.\n",
    "\n",
    "- Given problem is multiclass classification.There are different 101 news categories.\n",
    "- Given Data has Imbalanced Dataset.F-score with micro average is a useful evalution metrics when the classes are very imbalanced.(Some of the class has very high instances compare to others)\n",
    "- As shown in histogram of labels,The frequency of classes are very imbalanced\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3282.,  777.,  645.,  688.,  509.,  269.,   75., 1795.,    6.,\n",
       "        1954.]),\n",
       " array([ 0. ,  9.8, 19.6, 29.4, 39.2, 49. , 58.8, 68.6, 78.4, 88.2, 98. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "\n",
    "#plot votes frequency\n",
    "labels=df_new['labels']\n",
    "plt.xlabel('labels')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('frequency')\n",
    "plt.hist(labels,rwidth=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#function to get trained model \n",
    "def getTrainedClassfier(model,Train_X,Train_Y):\n",
    "    model=model.fit(Train_X, Train_Y)\n",
    "    return model\n",
    "\n",
    "#function to get model accuracy\n",
    "def getModelAccuracy(model,Test_X,Test_Y):\n",
    "    predition = model.predict(Test_X)\n",
    "    accuracy=accuracy_score(Test_Y, predition)\n",
    "    f_score=f1_score(Test_Y, predition, average='micro')  \n",
    "    print(\"Accuracy of model\",accuracy);\n",
    "    print(\"F-score of model\",f_score);\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model 0.4656666666666667\n",
      "F-score of model 0.4656666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB_model = MultinomialNB();\n",
    "NB_model=getTrainedClassfier(NB_model,Train_X,Train_Y)\n",
    "Accuracy=getModelAccuracy(NB_model,Test_X,Test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model 0.7676666666666667\n",
      "F-score of model 0.7676666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm_model =svm.SVC(kernel=\"linear\",gamma='auto')\n",
    "svm_model=getTrainedClassfier(svm_model,Train_X,Train_Y)\n",
    "Accuracy=getModelAccuracy(svm_model,Test_X,Test_Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model 0.6613333333333333\n",
      "F-score of model 0.6613333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "randomForest_model = RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "randomForest_model=getTrainedClassfier(randomForest_model,Train_X,Train_Y)\n",
    "Accuracy=getModelAccuracy(randomForest_model,Test_X,Test_Y)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model 0.5793333333333334\n",
      "F-score of model 0.5793333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decisionTreeModel = DecisionTreeClassifier()\n",
    "decisionTreeModel=getTrainedClassfier(decisionTreeModel,Train_X,Train_Y)\n",
    "Accuracy=getModelAccuracy(decisionTreeModel,Test_X,Test_Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model 0.7583333333333333\n",
      "F-score of model 0.7583333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlpClassifier_model = MLPClassifier(max_iter=400) \n",
    "mlpClassifier_model=getTrainedClassfier(mlpClassifier_model,Train_X,Train_Y)\n",
    "Accuracy=getModelAccuracy(mlpClassifier_model,Test_X,Test_Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "Linear Regression is not suitable for classification problem.\n",
    "1. In linear Regression predicted value is continuous,where in classification problem predicted value is categorical\n",
    "2. In linear Regression model, It try to find relation between features and lables data.There is linear relationship between x and y.\n",
    "\n",
    " - As per the predicted values and coefficient, In prediction it gives continuous value rather than categorical value.Linear regression model is not efficient for given problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient value [101.06188535 -13.88952026 -80.66125794 ... 492.61543982  -6.21142736\n",
      "   0.        ]\n",
      "predicted value [ 23.15603174 311.88208368  -1.17695365 ...  19.77456796 -91.37285922\n",
      " -37.81724754]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression().fit(Train_X, Train_Y)\n",
    "model.coef_\n",
    "predition = model.predict(Test_X)\n",
    "print(\"coefficient value\",model.coef_);\n",
    "print(\"predicted value\",predition);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuneClassifierFunction(model,param_grid):\n",
    "    grid_searchCV = GridSearchCV(estimator=model, param_grid=param_grid, cv= 5)\n",
    "    grid_searchCV=grid_searchCV.fit(Train_X, Train_Y)\n",
    "    return grid_searchCV\n",
    "\n",
    "def accuracyFunction(grid_searchCV):\n",
    "    print(\"best parameteres\",grid_searchCV.best_params_)\n",
    "    y_predict=grid_searchCV.predict(Test_X)\n",
    "    accuracy=accuracy_score(Test_Y, y_predict)\n",
    "    f_score=f1_score(Test_Y, y_predict, average='micro')  \n",
    "    print(\"F-score of model\",f_score);\n",
    "    print(\"Accuracy of model\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest model Tunning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhumipatel/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameteres {'min_samples_leaf': 1, 'n_estimators': 1000}\n",
      "F-score of model 0.6723333333333333\n",
      "Accuracy of model 0.6723333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "min_samples_leaf = [1,2,3]\n",
    "n_estimators=[1000,500]\n",
    "param_grid = {'min_samples_leaf': min_samples_leaf,'n_estimators': n_estimators}\n",
    "\n",
    "grid_searchCV=tuneClassifierFunction(randomForest_model,param_grid);\n",
    "accuracyFunction(grid_searchCV);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM model Tunning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhumipatel/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameteres {'gamma': 0.001, 'kernel': 'linear'}\n",
      "F-score of model 0.7676666666666666\n",
      "Accuracy of model 0.7676666666666667\n"
     ]
    }
   ],
   "source": [
    "# type of kernel value\n",
    "kernel=['linear','poly','rbf','sigmoid']\n",
    "gammas = [0.001, 0.01]\n",
    "param_grid = {'kernel': kernel,'gamma': gammas}\n",
    "grid_searchCV=tuneClassifierFunction(svm_model,param_grid);\n",
    "accuracyFunction(grid_searchCV);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTree model Tunning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhumipatel/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameteres {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2}\n",
      "F-score of model 0.5843333333333334\n",
      "Accuracy of model 0.5843333333333334\n"
     ]
    }
   ],
   "source": [
    "criterion=['gini','entropy']\n",
    "max_depth = [50,51]\n",
    "min_samples_split=[2,3,4]\n",
    "param_grid = {'criterion': criterion,'max_depth': max_depth,'min_samples_split':min_samples_split}\n",
    "grid_searchCV=tuneClassifierFunction(decisionTreeModel,param_grid); \n",
    "accuracyFunction(grid_searchCV);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nural network model Tunning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter=[400,600]\n",
    "solver= ['lbfgs','adam']\n",
    "hidden_layer_sizes=[100,200]\n",
    "\n",
    "param_grid = {'max_iter': max_iter,'solver': solver,'hidden_layer_sizes':hidden_layer_sizes}\n",
    "grid_searchCV=tuneClassifierFunction(mlpClassifier_model,param_grid)\n",
    "accuracyFunction(grid_searchCV);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model comparison : \n",
    "SVM and Neural Network both have good performance on given problem.\n",
    "\n",
    " <b>Model Performance :</b>\n",
    "\n",
    "-  Navie bayer = 0.4656666666666667\n",
    "-  SVM = 0.7676666666666667\n",
    "-  Random forest= 0.6613333333333333\n",
    "-  Decision tree= 0.5793333333333334\n",
    "-  nural network= 0.7583333333333333\n",
    "\n",
    "<b> SVM is best classifier for this text classification Problem.</b>\n",
    "\n",
    "1. SVM works efficiently even with many features because SVMs use overfitting protection, In text classification there are many features.\n",
    "2. SVM has ability to learn dimensionality of feature space independently.\n",
    "3. In text classification,each document contains few values which is not zero.SVM is suitable for dense concept problem.\n",
    "4. SVM Eliminate the feature selection which makes text classification easy.\n",
    "5. SVM gives higher accuracy without parameters tuning and it is faster compare to Neural network for this problem. \n",
    "6. SVM doen not need more training data to providing accurate results.It takes higher computation time compare to naive_bayes but give higher accuracy. \n",
    "7. SVM gave highest accuracy in given problem compare to other models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference\n",
    "1. https://www.cs.cornell.edu/people/tj/publications/joachims_98a.pdf\n",
    "2. https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "3. https://scikit-learn.org/stable/modules/grid_search.html\n",
    "4. https://scikit-learn.org/stable/modules/neural_networks_supervised.html\n",
    "5. https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "6. https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "7. https://scikit-learn.org/stable/modules/svm.html\n",
    "8. https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
